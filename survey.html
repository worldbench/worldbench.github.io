<!doctype html>
<html lang="en">
    <head>
        <title>3D and 4D World Modeling: A Survey</title>

        <link rel="icon" href="assets_common/icons/worldbench-circle.png" type="image/x-icon">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Rubik&display=swap" rel="stylesheet">

        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">

        <script src="./static/js/distill_template.v2.js"></script>
        <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

        <script src="https://d3js.org/d3.v5.min.js"></script>
        <script src="https://d3js.org/d3-collection.v1.min.js"></script>
        <script src="https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js"></script>

        <script defer="" src="./static/js/hider.js"></script>
        <script src="./static/js/image_interact.js"></script>
        <script src="./static/js/switch_videos.js"></script>

        <link rel="stylesheet" href="./static/css/style.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
        <script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>

        <script src="https://cdn.jsdelivr.net/npm/jquery@3.7.1/dist/jquery.min.js"></script>  <!-- jquery -->
        <script defer src="./static/js/medium-zoom.min.js"></script>
        <script defer src="./static/js/zoom.js"></script>

    </head>


    <body>
        <div class="header-wrapper">

            <div class="header-container", id="header-container">
                <div class="header-content">
                <h1 style="font-size:3.7rem;">
                  3D and 4D World Modeling: A Survey
                </h1>

                <h2 style="margin:2.2rem 0 1.8rem; display:flex; align-items:center; gap:0.4rem;">
                  <span class="icon is-small">
                    <img src="assets_common/icons/worldbench-circle.png" style="height:1.8em; vertical-align:text-top;">
                  </span>&nbsp;WorldBench Team
                </h2>


                <div class="button-container">
                    <a href="https://arxiv.org/abs/2509.07996" class="button paper-link" target="_blank">
                        <span class="icon is-small">
                            <i class="ai ai-arxiv "  style="height: 1.5em;"></i>
                        </span><span>arXiv</span>
                    </a>
                    <a href="assets_common/papers/survey.pdf" class="button paper-link" target="_blank">
                        <span class="icon is-small">
                            <img src="assets_common/icons/pdf.png" style="height: 1.4em;">
                        </span><span>PDF</span>
                    </a>
                    <a href="https://github.com/worldbench/survey" class="button" target="_blank">
                        <span class="icon is-small">
                            <img src="assets_common/icons/github.png" style="height: 1.4em;">
                        </span><span>GitHub</span>
                    </a>
                    <a href="https://huggingface.co/datasets/worldbench/videogen" class="button" target="_blank">
                        <span class="icon is-small">
                            <img src="assets_common/icons/hf.png" style="height: 1.5em;">
                        </span><span>Dataset</span>
                    </a>
                </div>
                </div>
                <div class="header-image">
                    <img src="assets/survey/figures/anni.webp" alt="header" class="teaser-image">
                </div>
            </div>
        </div>




        <d-article>
            <d-contents>
                <nav>
                    <h4>Contents</h4>
                    <div><a href="#definition">Definition</a></div>
                    <div><a href="#taxonomy">Taxonomy</a></div>
                    <div><a href="#examples">Examples</a></div>
                    <div><a href="#projects">Collections</a></div>
                    <div><a href="#contributors">Contributors</a></div>
                </nav>
            </d-contents>


            <section id="introduction">
              <div class="wb-section">
                <div class="wb-kicker">Introduction</div>
                <div class="wb-hr"></div>

                <p class="wb-lead">
                  World modeling has become a cornerstone in AI research, enabling agents to understand, represent, and predict the dynamic environments they inhabit.
                </p>
                <p class="wb-lead">
                  While prior work largely emphasizes generative methods for 2D image and video data, they overlook the rapidly growing body of work that leverages native 3D and 4D representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds for large-scale scene modeling.
                </p>

                <figure style="width: 100%; max-width: 1000px; display: block; margin: 32px auto;">
                  <img src="assets/survey/figures/teaser.png">
                </figure>

                <p class="wb-lead">
                  This survey reviews <strong>3D and 4D world models</strong> â€” models that learn, predict, and simulate the geometry and dynamics of real environments from multi-modal signals. 
                </p>
                <p class="wb-lead">
                  We unify terminology, scope, and evaluation, and organize the space into three complementary paradigms by representation: <strong>VideoGen</strong> (image/video-centric),
                  <strong>OccGen</strong> (occupancy-centric), and <strong>LiDARGen</strong> (point-cloud-centric).
                </p>
                <br><br>
              </div>
            </section>




            <section id="definition">
              <h2>Definition</h2>
              <!-- <div class="wb-hr" style="margin-bottom:1.25rem;"></div> -->

              <style>
                #definition .wb-grid{
                  grid-template-columns: 1fr !important;
                  max-width: 900px;
                  margin: 0 auto;
                  gap: 1rem 1.25rem;
                }
              </style>

              <div class="wb-grid">
                <!-- VideoGen -->
                <article class="wb-card">
                  <h3>
                    <i class="fas fa-film" aria-hidden="true"></i>
                    <a class="wb-anchor">VideoGen</a>
                  </h3>
                  <p>
                    <strong>What it is.</strong> An image/video-centric world model that generates or predicts
                    photorealistic, temporally consistent frames (single- or multi-view) conditioned on past context and optional controls.
                  </p>
                  <p class="wb-cap"><strong>Typical inputs</strong>: past frames, poses/camera intrinsics-extrinsics, text/route/action hints.</p>
                  <div class="wb-meta" aria-label="VideoGen tags">
                    <span class="wb-chip">Video Synthesis</span>
                    <span class="wb-chip">Future Prediction</span>
                    <span class="wb-chip">What-If Simulation</span>
                    <span class="wb-chip">Multi-View Generation</span>
                  </div>
                </article>

                <!-- OccGen -->
                <article class="wb-card">
                  <h3>
                    <i class="fas fa-cubes" aria-hidden="true"></i>
                    <a class="wb-anchor">OccGen</a>
                  </h3>
                  <p>
                    <strong>What it is.</strong> An occupancy-centric world model that represents scenes as 3D/4D occupancy
                    fields (e.g., voxel grids with semantics), enabling geometry-aware perception, forecasting, and simulation.
                  </p>
                  <p class="wb-cap"><strong>Typical inputs</strong>: multi-sensor cues (RGB, depth, events, LiDAR), ego motion, maps.</p>
                  <div class="wb-meta" aria-label="OccGen tags">
                    <span class="wb-chip">3D Reconstruction</span>
                    <span class="wb-chip">Occupancy Forecasting</span>
                    <span class="wb-chip">Autoregressive Simulation</span>
                    <span class="wb-chip">Semantic Voxel</span>
                  </div>
                </article>

                <!-- LiDARGen -->
                <article class="wb-card">
                  <h3>
                    <i class="fas fa-braille" aria-hidden="true"></i>
                    <a class="wb-anchor">LiDARGen</a>
                  </h3>
                  <p>
                    <strong>What it is.</strong> A point-cloud-centric world model that learns high-fidelity geometry and
                    dynamics directly from LiDAR sweeps, suitable for robust 3D understanding, data generation, and sensor-faithful simulation.
                  </p>
                  <p class="wb-cap"><strong>Typical inputs</strong>: past LiDAR sweeps, ego trajectory, calibration; optional scene priors.</p>
                  <div class="wb-meta" aria-label="LiDARGen tags">
                    <span class="wb-chip">Point Cloud Synthesis</span>
                    <span class="wb-chip">Future Sweeps</span>
                    <span class="wb-chip">Trajectory-Conditioned</span>
                    <span class="wb-chip">Physics-Aware</span>
                  </div>
                </article>
              </div>
              <br><br>
            </section>






            <section id="taxonomy">
              <h2>
                <span class="icon is-small">
                  <img src="assets_common/icons/worldbench.png" style="height: 1.2em;">
                </span>&nbsp;A Hierarchical Taxonomy</h2>
              <div class="wb-section">
                <p class="wb-lead">
                  We establish precise definitions, introduce a structured taxonomy spanning VideoGen, OccGen, and LiDARGen approaches, and systematically summarize datasets and evaluation metrics tailored to 3D/4D settings.
                </p>
                <figure style="width: 100%; max-width: 1000px; display: block; margin: 24px auto;">
                  <img src="assets/survey/figures/tree.png">
                </figure>
                <p class="wb-lead">
                  Together, these models provide the foundation for simulation, planning, and embodied intelligence in complex environments.
                </p>
              </div>
              <br><br>
            </section>


            <div class="wb-kicker"><span class="icon is-small">
                  <img src="assets/survey/figures/category.png" style="height: 1.6em;">
                </span>&nbsp;World Model Categorization</div>
            <div class="wb-hr" style="margin-bottom:1.25rem;"></div>

            <section id="model-types" style="margin:3.5rem 0;">
              <div>

                <p class="wb-lead">
                  We categorize 3D/4D world models into four functional types. They differ in how historical observations are
                  leveraged, which conditioning signals are provided,
                  and whether models operate in open-loop or closed-loop settings.
                </p>

                <div style="
                  display:grid;
                  grid-template-columns:repeat(2, minmax(0, 1fr));
                  gap:1.6rem 1.8rem;">

                  <!-- ================= Type 1 ================= -->
                  <article style="
                    background:#f9fafb;
                    border-radius:0.9rem;
                    padding:1rem 1.15rem;
                    box-shadow:0 1px 3px rgba(15,23,42,0.08);">

                    <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:0.45rem;">
                      <div style="
                        font-size:0.72rem;
                        font-weight:600;
                        letter-spacing:0.08em;
                        text-transform:uppercase;
                        color:#2563eb;">
                        Type 1
                      </div>
                      <div style="display:flex; align-items:center; gap:0.45rem; font-weight:600; color:#111827;">
                        Data Engines
                        <img src="assets/survey/figures/video-data-engine.png" style="height:1.6rem;">
                      </div>
                    </div>

                    <p style="font-size:0.9rem; line-height:1.7; color:#4b5563; margin:0 0 0.55rem;">
                      Generate diverse 3D/4D scenes from geometric and semantic cues, optionally with action conditions.
                      Focus on <b>plausibility</b> and <b>diversity</b> for large-scale data augmentation and scenario creation.
                    </p>

                    <ul style="padding-left:1.1rem; margin:0; font-size:0.88rem; line-height:1.6; color:#4b5563;">
                      <li><b>Inputs:</b> \(\mathcal{C}_{\mathrm{geo}}\), \(\mathcal{C}_{\mathrm{act}}\) (optional), \(\mathcal{C}_{\mathrm{sem}}\)</li>
                      <li><b>Output:</b> \(\mathcal{S}_g\) (generated scene)</li>
                    </ul>
                  </article>

                  <!-- ================= Type 2 ================= -->
                  <article style="
                    background:#f9fafb;
                    border-radius:0.9rem;
                    padding:1rem 1.15rem;
                    box-shadow:0 1px 3px rgba(15,23,42,0.08);">

                    <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:0.45rem;">
                      <div style="font-size:0.72rem; font-weight:600; letter-spacing:0.08em; color:#2563eb;">
                        Type 2
                      </div>
                      <div style="display:flex; align-items:center; gap:0.45rem; font-weight:600;">
                        Action Interpreters
                        <img src="assets/survey/figures/video-action-interpreter.png" style="height:1.6rem;">
                      </div>
                    </div>

                    <p style="font-size:0.9rem; line-height:1.7; color:#4b5563; margin:0 0 0.55rem;">
                      Forecast future 3D/4D world states from historical observations under given action conditions.
                      Enable <b>action-aware forecasting</b> for planning, behavior prediction, and policy evaluation.
                    </p>

                    <ul style="padding-left:1.1rem; margin:0; font-size:0.88rem; line-height:1.6; color:#4b5563;">
                      <li><b>Inputs:</b> \(\mathbf{x}_i^{-t:0}\), \(\mathcal{C}_{\mathrm{act}}\)</li>
                      <li><b>Output:</b> \(\mathcal{S}_p^{1:k}\) (predicted sequence)</li>
                    </ul>
                  </article>

                  <!-- ================= Type 3 ================= -->
                  <article style="
                    background:#f9fafb;
                    border-radius:0.9rem;
                    padding:1rem 1.15rem;
                    box-shadow:0 1px 3px rgba(15,23,42,0.08);">

                    <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:0.45rem;">
                      <div style="font-size:0.72rem; font-weight:600; letter-spacing:0.08em; color:#2563eb;">
                        Type 3
                      </div>
                      <div style="display:flex; align-items:center; gap:0.45rem; font-weight:600;">
                        Neural Simulators
                        <img src="assets/survey/figures/video-neural-simulator.png" style="height:1.4rem;">
                      </div>
                    </div>

                    <p style="font-size:0.9rem; line-height:1.7; color:#4b5563; margin:0 0 0.55rem;">
                      Iteratively simulate closed-loop agentâ€“environment interactions by generating successive scene states.
                      Support <b>interactive simulation</b> for autonomous driving, robotics, and immersive XR training.
                    </p>

                    <ul style="padding-left:1.1rem; margin:0; font-size:0.88rem; line-height:1.6; color:#4b5563;">
                      <li><b>Inputs:</b> \(\mathcal{S}_g^{t}\), \(\pi_{\mathrm{agent}}\)</li>
                      <li><b>Output:</b> \(\mathcal{S}_g^{t+1}\)</li>
                    </ul>
                  </article>

                  <!-- ================= Type 4 ================= -->
                  <article style="
                    background:#f9fafb;
                    border-radius:0.9rem;
                    padding:1rem 1.15rem;
                    box-shadow:0 1px 3px rgba(15,23,42,0.08);">

                    <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:0.45rem;">
                      <div style="font-size:0.72rem; font-weight:600; letter-spacing:0.08em; color:#2563eb;">
                        Type 4
                      </div>
                      <div style="display:flex; align-items:center; gap:0.45rem; font-weight:600;">
                        Scene Reconstructors
                        <img src="assets/survey/figures/video-scene-reconstructor.png" style="height:1.65rem;">
                      </div>
                    </div>

                    <p style="font-size:0.9rem; line-height:1.7; color:#4b5563; margin:0 0 0.55rem;">
                      Recover complete and coherent 3D/4D scenes from partial, sparse, or corrupted observations.
                      Facilitate <b>interactive tasks</b> such as high-fidelity mapping and digital twin restoration.
                    </p>

                    <ul style="padding-left:1.1rem; margin:0; font-size:0.88rem; line-height:1.6; color:#4b5563;">
                      <li><b>Inputs:</b> \(\mathbf{x}^{p}_{i}\), optional \(\mathcal{C}_{\mathrm{geo}}\)</li>
                      <li><b>Output:</b> \(\hat{\mathcal{S}}_{g}\) (completed scene)</li>
                    </ul>
                  </article>

                </div>
                <br>

                <p class="wb-lead">
                  Together, these four categories outline the functional landscape of 3D/4D world modeling.
                  While all aim to produce physically and semantically coherent scenes, they differ in how they
                  leverage past observations, conditioning signals, and interaction loopsâ€”supporting applications
                  from large-scale data synthesis and policy evaluation to interactive simulation and scene restoration.
                </p>

              </div>
              <br>
            </section>





            <style>
            #definition .wb-bridge {
              font-size: 1rem;
              line-height: 1.7;
              color: #374151;
              margin: 1rem 0 .75rem;
            }
            #definition .wb-grid-4 {
              display: grid;
              grid-template-columns: repeat(4, minmax(0, 1fr));
              gap: 1.25rem;
              margin-top: .5rem;
            }
            @media (max-width: 1200px) {
              #definition .wb-grid-4 { grid-template-columns: repeat(3, minmax(0, 1fr)); }
            }
            @media (max-width: 1024px) {
              #definition .wb-grid-4 { grid-template-columns: repeat(2, minmax(0, 1fr)); }
            }
            @media (max-width: 640px) {
              #definition .wb-grid-4 { grid-template-columns: 1fr; }
            }
            #definition .wb-card h4 {
              display: flex; align-items: center; gap: .5rem;
              font-size: 1rem; margin: 0 0 .35rem;
            }
            #definition .wb-card p.small {
              margin: .35rem 0; color: #4b5563; line-height: 1.6;
            }
          </style>





            <section id="examples">
                <h2>Generated 3D & 4D Contents</h2>

                <div class="wb-kicker"><span class="icon is-small">
                    <img src="assets_common/icons/bench_videogen.png" style="height: 1.5em;">
                  </span>&nbsp;VideoGen</div>
                <div class="wb-hr" style="margin-bottom:1.25rem;"></div>

                <section class="videogen" tabindex="0" aria-label="VideoGen Set A">
                    <div class="video-hero">
                      <video autoplay loop muted playsinline data-hero>
                        <source src="assets/survey/videos/gt_0.mp4" type="video/mp4" />
                      </video>
                      <div class="video-badge" data-hero-label>Reference</div>
                    </div>
                  
                    <div class="thumb-bar" role="tablist" aria-label="Video methods A">
                      <button class="thumb is-active" role="tab" aria-selected="true"
                              data-src="assets/survey/videos/gt_0.mp4" data-label="Reference">
                        <img src="assets/survey/videos/images/gt_0.png" />
                        <span>Reference</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/magicdrive_0.mp4" data-label="MagicDrive">
                        <img src="assets/survey/videos/images/magicdrive_0.png" />
                        <span>MagicDrive</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/drivedreamer2_0.mp4" data-label="Drivedreamer2">
                        <img src="assets/survey/videos/images/drivedreamer2_0.png" />
                        <span>DriveDreamer-2</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/dreamforge_0.mp4" data-label="Dreamforge">
                        <img src="assets/survey/videos/images/dreamforge_0.png" />
                        <span>DreamForge</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/opendwm_0.mp4" data-label="OpenDWM">
                        <img src="assets/survey/videos/images/opendwm_0.png" />
                        <span>OpenDWM</span>
                      </button>
                    </div>
                  </section>

                  <p></p>

                  <section class="videogen" tabindex="0" aria-label="VideoGen Set B">
                    <div class="video-hero">
                      <video autoplay loop muted playsinline data-hero>
                        <source src="assets/survey/videos/gt_1.mp4" type="video/mp4" />
                      </video>
                      <div class="video-badge" data-hero-label>Reference</div>
                    </div>
                  
                    <div class="thumb-bar" role="tablist" aria-label="Video methods A">
                      <button class="thumb is-active" role="tab" aria-selected="true"
                              data-src="assets/survey/videos/gt_1.mp4" data-label="Reference">
                        <img src="assets/survey/videos/images/gt_1.png" />
                        <span>Reference</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/magicdrive_1.mp4" data-label="MagicDrive">
                        <img src="assets/survey/videos/images/magicdrive_1.png" />
                        <span>MagicDrive</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/drivedreamer2_1.mp4" data-label="Drivedreamer2">
                        <img src="assets/survey/videos/images/drivedreamer2_1.png" />
                        <span>DriveDreamer-2</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/dreamforge_1.mp4" data-label="Dreamforge">
                        <img src="assets/survey/videos/images/dreamforge_1.png" />
                        <span>DreamForge</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/opendwm_1.mp4" data-label="OpenDWM">
                        <img src="assets/survey/videos/images/opendwm_1.png" />
                        <span>OpenDWM</span>
                      </button>
                    </div>

                    <p></p>

                  <section class="videogen" tabindex="0" aria-label="VideoGen Set C">
                    <div class="video-hero">
                      <video autoplay loop muted playsinline data-hero>
                        <source src="assets/survey/videos/gt_2.mp4" type="video/mp4" />
                      </video>
                      <div class="video-badge" data-hero-label>Reference</div>
                    </div>
                  
                    <div class="thumb-bar" role="tablist" aria-label="Video methods C">
                      <button class="thumb is-active" role="tab" aria-selected="true"
                              data-src="assets/survey/videos/gt_2.mp4" data-label="Reference">
                        <img src="assets/survey/videos/images/gt_2.jpg" />
                        <span>Reference</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/magicdrive_2.mp4" data-label="MagicDrive">
                        <img src="assets/survey/videos/images/magicdrive_2.jpg" />
                        <span>MagicDrive</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/drivedreamer2_2.mp4" data-label="Drivedreamer2">
                        <img src="assets/survey/videos/images/drivedreamer2_2.jpg" />
                        <span>DriveDreamer-2</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/dreamforge_2.mp4" data-label="Dreamforge">
                        <img src="assets/survey/videos/images/dreamforge_2.jpg" />
                        <span>DreamForge</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/videos/opendwm_2.mp4" data-label="OpenDWM">
                        <img src="assets/survey/videos/images/opendwm_2.jpg" />
                        <span>OpenDWM</span>
                      </button>
                    </div>


                    <br><br>
                  </section>




                

                <div class="wb-kicker"><span class="icon is-small">
                    <img src="assets_common/icons/bench_occgen.png" style="height: 1.5em;">
                  </span>OccGen</div>
                <div class="wb-hr" style="margin-bottom:1.25rem;"></div>


                  <section class="videogen" tabindex="0" aria-label="VideoGen Set C">
                    <div class="video-hero">
                      <video autoplay loop muted playsinline data-hero>
                        <source src="assets/survey/occ_videos/dynamic_video/0_occ.mp4" type="video/mp4" />
                      </video>
                      <div class="video-badge" data-hero-label>Sample 1</div>
                    </div>
                  
                    <div class="thumb-bar" role="tablist" aria-label="Video methods A">
                      <button class="thumb is-active" role="tab" aria-selected="true"
                              data-src="assets/survey/occ_videos/dynamic_video/1_occ.mp4" data-label="Sample1">
                        <img src="assets/survey/occ_videos/dynamic_video/0_bev_layout.png" alt="Reference thumbnail" />
                        <span>Sample 1</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/occ_videos/dynamic_video/1_occ.mp4" data-label="Sample2">
                        <img src="assets/survey/occ_videos/dynamic_video/1_bev_layout.png" alt="MagicDrive thumbnail" />
                        <span>Sample 2</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/occ_videos/dynamic_video/2_occ.mp4" data-label="Sample3">
                        <img src="assets/survey/occ_videos/dynamic_video/2_bev_layout.png" alt="MagicDrive thumbnail" />
                        <span>Sample 3</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/occ_videos/dynamic_video/3_occ.mp4" data-label="Sample4">
                        <img src="assets/survey/occ_videos/dynamic_video/3_bev_layout.png" alt="MagicDrive thumbnail" />
                        <span>Sample 4</span>
                      </button>
                      <button class="thumb" role="tab" aria-selected="false"
                              data-src="assets/survey/occ_videos/dynamic_video/4_occ.mp4" data-label="Sample5">
                        <img src="assets/survey/occ_videos/dynamic_video/4_bev_layout.png" alt="MagicDrive thumbnail" />
                        <span>Sample 5</span>
                      </button>
                    </div>
                    <br><br>
                  </section>




                <div class="wb-kicker"><span class="icon is-small">
                    <img src="assets_common/icons/bench_lidargen.png" style="height: 1.5em;">
                  </span>LiDARGen</div>
                <div class="wb-hr" style="margin-bottom:1.25rem;"></div>


                  <details class="data-switcher lazy-load"
                    aria-label="LiDAR Data Showcase"
                    data-client="https://worldbench.github.io/viser-client/"
                    data-base="https://worldbench.github.io/assets/survey/lidar_visers/"
                    data-query="&initialCameraPosition=10.885,9.746,4.995&initialCameraLookAt=2.343,1.204,-3.547&initialCameraUp=-0.000,-0.000,1.000">
                    <summary>(click to expand)</summary>

                    <div class="grid-2x2">
                      <iframe class="viseriframe" data-file="0.viser" loading="lazy" allowfullscreen></iframe>
                      <iframe class="viseriframe" data-file="1.viser" loading="lazy" allowfullscreen></iframe>
                      <iframe class="viseriframe" data-file="2.viser" loading="lazy" allowfullscreen></iframe>
                      <iframe class="viseriframe" data-file="3.viser" loading="lazy" allowfullscreen></iframe>
                    </div>

                    <div class="method-bar" role="tablist" aria-label="Methods">
                      <button class="method-btn is-active" role="tab" aria-selected="true"  data-method="lidargen">LiDARGen</button>
                      <button class="method-btn"           role="tab" aria-selected="false" data-method="lidm">LiDM</button>
                      <button class="method-btn"           role="tab" aria-selected="false" data-method="r2dm">R2DM</button>
                      <button class="method-btn"           role="tab" aria-selected="false" data-method="uniscene">UniScene</button>
                      <button class="method-btn"           role="tab" aria-selected="false" data-method="opendwm">OpenDWM</button>
                      <button class="method-btn"           role="tab" aria-selected="false" data-method="lidarcrafter">LiDARCrafter</button>
                    </div>
                  </details>
                  <br><br>
            </section>









            <section id="projects">
                <h2>Collections</h2>
                <!-- <div class="wb-hr" style="margin-bottom:1.25rem;"></div> -->
            </section>

            <section id="video-papers" class="papers-section" data-section-key="video" data-initial="3">
                <h2>Video Generation</h2>
                <div class="bar" aria-live="polite">
                  <div class="tabs" role="tablist" aria-label="Video Generation Categories">
                    <button class="tab-btn tab-1" role="tab" aria-selected="true" aria-controls="video-panel-a" id="video-tab-a">Data Engines</button>
                    <button class="tab-btn tab-2" role="tab" aria-selected="false" aria-controls="video-panel-b" id="video-tab-b">Action Interpreters</button>
                    <button class="tab-btn tab-3" role="tab" aria-selected="false" aria-controls="video-panel-c" id="video-tab-c">Neural Simulators</button>
                    <button class="tab-btn tab-4" role="tab" aria-selected="false" aria-controls="video-panel-d" id="video-tab-d">Scene Reconstructors</button>
  
                </div>
                  <div class="search" title="è¾“å…¥å…³é”®è¯è¿‡æ»¤ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å‡ºå¤„ï¼‰">
                    ðŸ”Ž <input class="paper-search" type="search" placeholder="Search: Title / Author / Source" />
                  </div>
                  <span class="count">0 items</span>
                </div>
                <section id="video-panel-a" class="panel" role="tabpanel" aria-labelledby="video-tab-a" aria-hidden="false">
                  <div class="list"></div>
                </section>
                <section id="video-panel-b" class="panel" role="tabpanel" aria-labelledby="video-tab-b" aria-hidden="true">
                  <div class="list"></div>
                </section>
                <section id="video-panel-c" class="panel" role="tabpanel" aria-labelledby="video-tab-c" aria-hidden="true">
                  <div class="list"></div>
                </section>
                <section id="video-panel-d" class="panel" role="tabpanel" aria-labelledby="video-tab-d" aria-hidden="true">
                  <div class="list"></div>
                </section>
              </section>

              
              <section id="projects">
                <hr>
              </section>


            <section id="occupancy-papers" class="papers-section" data-section-key="occupancy">
                <h2>Occupancy Generation</h2>
                <div class="bar" aria-live="polite">
                  <div class="tabs" role="tablist" aria-label="Occupancy Generation Categories">
                    <button class="tab-btn tab-1" role="tab" aria-selected="true" aria-controls="occupancy-panel-a" id="occupancy-tab-a">Scene Representors</button>
                    <button class="tab-btn tab-2" role="tab" aria-selected="false" aria-controls="occupancy-panel-b" id="occupancy-tab-b">Occupancy Forecasters</button>
                    <button class="tab-btn tab-3" role="tab" aria-selected="false" aria-controls="occupancy-panel-c" id="occupancy-tab-c">Autoregressive Simulators</button>
                    <!-- <button class="tab-btn tab-4" role="tab" aria-selected="false" aria-controls="video-panel-d" id="video-tab-d">Scene Reconstructors</button>   -->
                </div>
                  <div class="search" title="è¾“å…¥å…³é”®è¯è¿‡æ»¤ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å‡ºå¤„ï¼‰">
                    ðŸ”Ž <input class="paper-search" type="search" placeholder="Search: Title / Author / Source" />
                  </div>
                  <span class="count">0 items</span>
                </div>
                <section id="occupancy-panel-a" class="panel" role="tabpanel" aria-labelledby="occupancy-tab-a" aria-hidden="false">
                  <div class="list"></div>
                </section>
                <section id="occupancy-panel-b" class="panel" role="tabpanel" aria-labelledby="occupancy-tab-b" aria-hidden="true">
                  <div class="list"></div>
                </section>
                <section id="occupancy-panel-c" class="panel" role="tabpanel" aria-labelledby="occupancy-tab-c" aria-hidden="true">
                  <div class="list"></div>.grid-2x2{
                    display: grid;
                    grid-template-columns: repeat(2, minmax(0, 1fr));
                    align-items: start;
                    gap: 12px;
                  }
                  .viseriframe{
                    width: 100%;
                    height: auto; 
                    border: 0;
                    border-radius: 8px;
                  }
                </section>
                <section id="video-panel-d" class="panel" role="tabpanel" aria-labelledby="video-tab-d" aria-hidden="true">
                    <div class="list"></div>
                </section>
              </section>


              <section id="projects">
                <hr>
              </section>



              <section id="lidar-papers" class="papers-section" data-section-key="lidar">
                <h2>LiDAR Generation</h2>
                <div class="bar" aria-live="polite">
                  <div class="tabs" role="tablist" aria-label="LiDAR Generation Categories">
                    <button class="tab-btn tab-1" role="tab" aria-selected="true" aria-controls="lidar-panel-a" id="lidar-tab-a">Data Engines</button>
                    <button class="tab-btn tab-2" role="tab" aria-selected="false" aria-controls="lidar-panel-b" id="lidar-tab-b">Action Interpreters</button>
                    <button class="tab-btn tab-3" role="tab" aria-selected="false" aria-controls="lidar-panel-c" id="lidar-tab-c">Autoregressive Simulators</button>
                  </div>
                  <div class="search" title="è¾“å…¥å…³é”®è¯è¿‡æ»¤ï¼ˆæ ‡é¢˜ã€ä½œè€…ã€å‡ºå¤„ï¼‰">
                    ðŸ”Ž <input class="paper-search" type="search" placeholder="Search: Title / Author / Source" />
                  </div>
                  <span class="count">0 items</span>
                </div>
                <section id="lidar-panel-a" class="panel" role="tabpanel" aria-labelledby="lidar-tab-a" aria-hidden="false">
                  <div class="list"></div>
                </section>
                <section id="lidar-panel-b" class="panel" role="tabpanel" aria-labelledby="lidar-tab-b" aria-hidden="true">
                  <div class="list"></div>
                </section>
                <section id="lidar-panel-c" class="panel" role="tabpanel" aria-labelledby="lidar-tab-c" aria-hidden="true">
                  <div class="list"></div>
                </section>
                <section id="video-panel-d" class="panel" role="tabpanel" aria-labelledby="video-tab-d" aria-hidden="true">
                    <div class="list"></div>
                </section>
              </section>



            <br>

            
            
            <!-- <d-appendix>
                <h3>BibTeX</h3>
                <p class="bibtex">
                    @article{kong2025worldbench,<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;title={WorldBench: Benchmarking 3D and 4D World Models in the Real World},<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;author={WorldBench Team},<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;journal={arXiv preprint arXiv:2508.xxxxx},<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;year={2025},<br>
                    }
                </p>

                <d-footnote-list></d-footnote-list>
                <d-citation-list></d-citation-list>
            </d-appendix> -->





            <section id="contributors">
              <div class="wb-section">
                <br>
                <hr>

                <div class="wb-kicker">
                <span class="icon is-small">
                    <img src="assets_common/icons/worldbench.png" style="height: 1.5em;">
                  </span>&nbsp;List of Contributors</div>
                <div class="wb-hr"></div>

                
                <div class="contributors-list">
                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/lingdong_kong.jpg" 
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Lingdong Kong</div>
                      <div class="contributor-note">Core Contributor, Project Lead</div>
                    </div>
                    <div class="contributor-links">
                      <a href="mailto:lingdong.kong@u.nus.edu" aria-label="Email"><i class="fas fa-envelope"></i> </a>
                      <a href="https://ldkong.com" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=-j1j7TkAAAAJ" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/ldkong1205/" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="https://www.linkedin.com/in/ldkong/" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                      <a href="https://twitter.com/ldkong1205" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/icons/worldbench-circle.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Wesley Yang</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/jianbiao_mei.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Jianbiao Mei</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>
                  

                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/youquan_liu.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Youquan Liu</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://openreview.net/profile?id=~Youquan_Liu1" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=J9a48hMAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/youquanl" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/ao_liang.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Ao Liang</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://alanliangc.github.io/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=ocyBGGYAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/AlanLiangC" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/dekai_zhu.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Dekai Zhu</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://dekai21.github.io/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=rehMAJUAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/Dekai21" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="https://de.linkedin.com/in/dekai-zhu-621573208" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/dongyue_lu.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Dongyue Lu</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/wei_yin.jpeg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Wei Yin</div>
                      <div class="contributor-note">Core Contributor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://yvanyin.xyz/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=ZIf_rtcAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/YvanYin" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="https://www.linkedin.com/in/wei-yin-28b64b167/" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/xiaotao_hu.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Xiaotao Hu</div>
                      <div class="contributor-note">Contributor, VideoGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/mingkai_jia.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Mingkai Jia</div>
                      <div class="contributor-note">Contributor, VideoGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/junyuan_deng.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Junyuan Deng</div>
                      <div class="contributor-note">Contributor, VideoGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/kaiwen_zhang.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Kaiwen Zhang</div>
                      <div class="contributor-note">Contributor, VideoGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/yang_wu.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Yang Wu</div>
                      <div class="contributor-note">Contributor, LiDARGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/tianyi_yan.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Tianyi Yan</div>
                      <div class="contributor-note">Contributor, LiDARGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://yanty123.github.io/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com.hk/citations?user=0JmbnNQAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/yanty123" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/shenyuan_gao.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Shenyuan Gao</div>
                      <div class="contributor-note">Contributor, VideoGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/song_wang.jpeg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Song Wang</div>
                      <div class="contributor-note">Contributor, OccGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/linfeng_li.jpeg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Linfeng Li</div>
                      <div class="contributor-note">Contributor, OccGen</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/liang_pan.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Liang Pan</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/yong_liu.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Yong Liu</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/jianke_zhu.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Jianke Zhu</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/wei_tsang_ooi.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Wei Tsang Ooi</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://www.comp.nus.edu.sg/cs/people/ooiwt/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=nFP2ldkAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/weitsang" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="https://sg.linkedin.com/in/weitsang" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                      <a href="https://x.com/weitsang/" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/steven_c_h_hoi.jpg"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Steven C. H. Hoi</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://sites.google.com/view/stevenhoi/home" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=JoLjflYAAAAJ&hl=en" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://www.linkedin.com/in/steven-hoi-8712b41/" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                      <a href="https://x.com/stevenhoi" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>


                  <!-- Row -->
                  <div class="contributor-row">
                    <img class="contributor-photo"
                        src="assets_common/photos/ziwei_liu.png"
                        loading="lazy" width="56" height="56">

                    <div class="contributor-text">
                      <div class="contributor-name">Ziwei Liu</div>
                      <div class="contributor-note">Advisor</div>
                    </div>
                    <div class="contributor-links">
                      <a href="https://liuziwei7.github.io/" target="_blank" aria-label="Homepage"><i class="fas fa-globe"></i> </a>
                      <a href="https://scholar.google.com/citations?user=lc45xlcAAAAJ" target="_blank" aria-label="Google Scholar"> <i class="ai ai-google-scholar"></i> </a>
                      <a href="https://github.com/liuziwei7" target="_blank" aria-label="GitHub"> <i class="fab fa-github"></i> </a>
                      <a href="https://sg.linkedin.com/in/ziwei-liu-852b265a" target="_blank" aria-label="LinkedIn"> <i class="fab fa-linkedin"></i> </a>
                      <a href="https://twitter.com/liuziwei7" target="_blank" aria-label="X (Twitter)"> <i class="fab fa-twitter"> </i> </a>
                    </div>
                  </div>

                </div>
                <br>
              </div>
              <br><br>
            </section>


            <br><br>


            <footer class="wb-footer">
              <br>
              <div class="wb-footer-content">
                <p>
                  This website is licensed under a
                  <a href="https://creativecommons.org/licenses/by-sa/4.0/"
                    target="_blank"
                    rel="noopener noreferrer">
                    Creative Commons Attribution-ShareAlike 4.0 International License
                  </a>
                </p>
                <p>
                  Â© WorldBench 2025-2026. All Rights Reserved
                </p>
              </div>
              <br>
            </footer>


        </d-article>











        
        <script src="contents_bar.js"></script>

        <script>

          const paperStore = {
            video: {
              A: [
              { title:"BEVControl: Accurately Controlling Street-View Elements with Multi-Perspective Consistency via BEV Sketch Layout", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2308.01661", code:"#", project:"#"},
                { title:"Street-View Image Generation from a Bird's-Eye View Layout", authors:"", venue:"RA-L", year:2024, paper:"https://arxiv.org/abs/2301.04634", code:"https://github.com/alexanderswerdlow/BEVGen", project:"https://metadriverse.github.io/bevgen/"},
                { title:"MagicDrive: Street View Generation with Diverse 3D Geometry Control", authors:"", venue:"ICLR", year:2024, paper:"https://arxiv.org/abs/2310.02601", code:"https://github.com/cure-lab/MagicDrive", project:"https://gaoruiyuan.com/magicdrive/"},
                { title:"Panacea: Panoramic and Controllable Video Generation for Autonomous Driving", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2311.16813", code:"https://github.com/wenyuqing/panacea", project:"https://panacea-ad.github.io/"},
                { title:"DrivingDiffusion: Layout-Guided Multi-View Driving Scene Video Generation with Latent Diffusion Model", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2310.07771", code:"https://github.com/shalfun/DrivingDiffusion", project:"https://drivingdiffusion.github.io/"},
                { title:"WoVoGen: World Volume-Aware Diffusion for Controllable Multi-Camera Driving Scene Generation", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2312.02934", code:"https://github.com/fudan-zvg/WoVoGen", project:"#"},
                { title:"Unleashing Generalization of End-to-End Autonomous Driving with Controllable Long Video Generation (Delphi)", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2406.01349", code:"https://github.com/westlake-autolab/Delphi", project:"https://westlake-autolab.github.io/delphi.github.io/"},
                { title:"SimGen: Simulator-conditioned Driving Scene Generation", authors:"", venue:"NeurIPS", year:2024, paper:"https://arxiv.org/abs/2406.09386", code:"https://github.com/metadriverse/SimGen", project:"https://metadriverse.github.io/simgen/"},
                { title:"BEVWorld: A Multimodal World Simulator for Autonomous Driving via Scene-Level BEV Latents", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2407.05679", code:"#", project:"#"},
                { title:"Panacea+: Panoramic and Controllable Video Generation for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2408.07605", code:"#", project:"https://panacea-ad.github.io/"},
                { title:"DiVE: DiT-Based Video Generation with Enhanced Control", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2409.01595", code:"https://github.com/LiAutoAD/DIVE", project:"https://liautoad.github.io/DIVE/"},
                { title:"SyntheOcc: Synthesize Geometric-Controlled Street View Images through 3D Semantic MPIs", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2410.00337", code:"https://github.com/EnVision-Research/SyntheOcc", project:"https://len-li.github.io/syntheocc-web/"},
                { title:"HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.01407", code:"#", project:"#"},
                { title:"Seeing Beyond Views: Multi-View Driving Scene Video Generation with Holistic Attention (CogDriving)", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.03520", code:"#", project:"https://luhannan.github.io/CogDrivingPage/"},
                { title:"UniMLVG: Unified Framework for Multi-View Long Video Generation with Comprehensive Control Capabilities for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.04842", code:"https://github.com/SenseTime-FVG/OpenDWM", project:"#"},
                { title:"Physical Informed Driving World Model (DrivePhysica)", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.08410", code:"#", project:"https://metadrivescape.github.io/papers_project/DrivePhysica/page.html"},
                { title:"DriveDreamer-2: LLM-Enhanced World Models for Diverse Driving Video Generation", authors:"", venue:"AAAI", year:2025, paper:"https://arxiv.org/abs/2403.06845", code:"https://github.com/f1yfisher/DriveDreamer2", project:"https://drivedreamer2.github.io/"},
                { title:"SubjectDrive: Scaling Generative Data in Autonomous Driving via Subject Control", authors:"", venue:"AAAI", year:2025, paper:"https://arxiv.org/abs/2403.19438", code:"#", project:"https://subjectdrive.github.io/"},
                { title:"Glad: A Streaming Scene Generator for Autonomous Driving", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2503.00045", code:"https://github.com/xb534/Glad", project:"#"},
                { title:"DualDiff: Dual-Branch Diffusion Model for Autonomous Driving with Semantic Fusion", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2505.01857", code:"https://github.com/yangzhaojason/DualDiff", project:"#"},
                { title:"UniScene: Unified Occupancy-Centric Driving Scene Generation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2412.05435", code:"https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation", project:"https://arlo0o.github.io/uniscene/"},
                { title:"DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2409.05463", code:"#", project:"https://metadrivescape.github.io/papers_project/drivescapev1/index.html"},
                { title:"PerLDiff: Controllable Street View Synthesis Using Perspective-Layout Diffusion Models", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2407.06109", code:"https://github.com/LabShuHangGU/PerlDiff", project:"https://perldiff.github.io/"},
                { title:"MagicDrive-V2: High-Resolution Long Video Generation for Autonomous Driving with Adaptive Control", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2411.13807", code:"#", project:"https://gaoruiyuan.com/magicdrive-v2/"},
                { title:"Cosmos-Transfer1: Conditional World Generation with Adaptive Multimodal Control", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.14492", code:"https://github.com/nvidia-cosmos/cosmos-transfer1", project:"https://research.nvidia.com/labs/dir/cosmos-transfer1/"},
                { title:"DualDiff+: Dual-Branch Diffusion for High-Fidelity Video Generation with Reward Guidance", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.03689", code:"https://github.com/yangzhaojason/DualDiff", project:"#"},
                { title:"CoGen: 3D Consistent Video Generation via Adaptive Conditioning for Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.22231", code:"#", project:"https://xiaomi-research.github.io/cogen/"},
                { title:"NoiseController: Towards Consistent Multi-View Video Generation via Noise Decomposition and Collaboration", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2504.18448", code:"#", project:"#"},
                { title:"STAGE: A Stream-Centric Generative World Model for Long-Horizon Driving-Scene Simulation", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.13138", code:"#", project:"#"}
              ],
              B: [
              { title:"GAIA-1: A Generative World Model for Autonomous Driving", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2309.17080", code:"#", project:"https://wayve.ai/thinking/scaling-gaia-1/" },
                { title:"ADriver-I: A General World Model for Autonomous Driving", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2311.13549", code:"#", project:"#"},
                { title:"Driving into the Future: Multiview Visual Forecasting and Planning with World Model for Autonomous Driving (Drive-WM)", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2311.17918", code:"https://github.com/BraveGroup/Drive-WM", project:"https://drive-wm.github.io/" },
                { title:"DriveDreamer: Towards Real-World-Driven World Models for Autonomous Driving", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2309.09777", code:"https://github.com/JeffWang987/DriveDreamer", project:"https://drivedreamer.github.io/" },
                { title:"GenAD: Generalized Predictive Model for Autonomous Driving", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2403.09630", code:"https://github.com/OpenDriveLab/DriveAGI", project:"#"},
                { title:"Vista: A Generalizable Driving World Model with High Fidelity and Versatile Controllability", authors:"", venue:"NeurIPS", year:2024, paper:"https://arxiv.org/abs/2405.17398", code:"https://github.com/OpenDriveLab/Vista", project:"https://vista-demo.github.io/" },
                { title:"InfinityDrive: Breaking Time Limits in Driving World Models", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.01522", code:"#", project:"https://metadrivescape.github.io/papers_project/InfinityDrive/page.html" },
                { title:"DrivingGPT: Unifying Driving World Modeling and Planning with Multi-Modal Autoregressive Transformers", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.18607", code:"#", project:"https://rogerchern.github.io/DrivingGPT/" },
                { title:"DrivingWorld: Constructing World Model for Autonomous Driving via Video GPT", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.19505", code:"https://github.com/YvanYin/DrivingWorld", project:"https://huxiaotaostasy.github.io/DrivingWorld/index.html" },
                { title:"GEM: A Generalizable Ego-Vision Multimodal World Model for Fine-Grained Ego-Motion, Object Dynamics, and Scene Composition Control", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2412.11198", code:"https://github.com/vita-epfl/GEM", project:"https://vita-epfl.github.io/GEM.github.io/" },
                { title:"MaskGWM: A Generalizable Driving World Model with Video Mask Reconstruction", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2502.11663", code:"https://github.com/SenseTime-FVG/OpenDWM", project:"#"},
                { title:"Epona: Autoregressive Diffusion World Model for Autonomous Driving", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2506.24113", code:"https://github.com/Kevin-thu/Epona", project:"https://kevin-thu.github.io/Epona/" },
                { title:"VaViM and VaVAM: Autonomous Driving through Video Generative Modeling", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2502.15672", code:"https://github.com/valeoai/VideoActionModel", project:"https://valeoai.github.io/vavim-vavam/" },
                { title:"MiLA: Multi-View Intensive-Fidelity Long-Term Video Generation World Model for Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.15875", code:"https://github.com/xiaomi-mlab/mila.github.io", project:"#"},
                { title:"GAIA-2: A Controllable Multi-View Generative World Model for Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.20523", code:"#", project:"https://wayve.ai/thinking/gaia-2" },
                { title:"DriVerse: Navigation World Model for Driving Simulation via Multimodal Trajectory Prompting and Motion Alignment", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2504.18576", code:"#", project:"#"},
                { title:"PosePilot: Steering Camera Pose for Generative World Models with Self-Supervised Depth", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.01729", code:"#", project:"#"},
                { title:"ProphetDWM: A Driving World Model for Rolling Out Future Actions and Videos", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.18650", code:"#", project:"#"},
                { title:"LongDWM: Cross-Granularity Distillation for Building A Long-Term Driving World Model", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.01546", code:"https://github.com/Wang-Xiaodong1899/Long-DWM", project:"https://wang-xiaodong1899.github.io/longdwm/" }
              ],
              C: [
              { title:"MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2405.14475", code:"https://github.com/flymin/MagicDrive3D", project:"https://gaoruiyuan.com/magicdrive3d/" },
                { title:"DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2409.04003", code:"https://github.com/PJLab-ADG/DriveArena", project:"https://pjlab-adg.github.io/DriveArena/dreamforge/" },
                { title:"Doe-1: Closed-Loop Autonomous Driving with Large World Model", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.09627", code:"https://github.com/wzzheng/Doe", project:"https://wzzheng.net/Doe/" },
                { title:"DrivingSphere: Building A High-Fidelity 4D World for Closed-Loop Simulation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.11252", code:"https://github.com/yanty123/DrivingSphere", project:"https://yanty123.github.io/DrivingSphere/" },
                { title:"UMGen: Generating Multimodal Driving Scenes via Next-Scene Prediction", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2503.14945", code:"https://github.com/YanhaoWu/UMGen", project:"https://yanhaowu.github.io/UMGen/" },
                { title:"DriveArena: A Closed-Loop Generative Simulation Platform for Autonomous Driving", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2408.00415", code:"https://github.com/PJLab-ADG/DriveArena", project:"https://pjlab-adg.github.io/DriveArena/" },
                { title:"InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2412.03934", code:"https://github.com/nv-tlabs/InfiniCube", project:"https://research.nvidia.com/labs/toronto-ai/infinicube/" },
                { title:"DiST-4D: Disentangled Spatiotemporal Diffusion with Metric Depth for 4D Driving Scene Generation", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2503.15208", code:"https://github.com/royalmelon0505/dist4d", project:"https://royalmelon0505.github.io/DiST-4D/" },
                { title:"UniFuture: A Unified Driving World Model for Future Generation and Perception", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.13587", code:"https://github.com/dk-liang/UniFuture", project:"https://dk-liang.github.io/UniFuture/" },
                { title:"Nexus: Decoupled Diffusion Sparks Adaptive Scene Generation", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2504.10485", code:"https://github.com/OpenDriveLab/Nexus", project:"https://opendrivelab.com/Nexus/" },
                { title:"Challenger: Affordable Adversarial Driving Video Generation", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.15880", code:"https://github.com/Pixtella/Challenger", project:"https://pixtella.github.io/Challenger/" },
                { title:"Cosmos-Drive-Dreams: Scalable Synthetic Driving Data Generation with World Foundation Models", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.09042", code:"https://github.com/nv-tlabs/Cosmos-Drive-Dreams", project:"https://research.nvidia.com/labs/toronto-ai/cosmos_drive_dreams/" }
              ],
              D: [
              { title:"3D Gaussian Splatting for Real-Time Radiance Field Rendering", authors:"", venue:"TOG", year:2023, paper:"https://arxiv.org/abs/2401.01339", code:"https://github.com/graphdeco-inria/gaussian-splatting", project:"https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/" },
                { title:"Street Gaussians: Modeling Dynamic Urban Scenes with Gaussian Splatting", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2401.01339", code:"https://github.com/zju3dv/street_gaussians", project:"https://zju3dv.github.io/street_gaussians" },
                { title:"Dynamic 3D Gaussian Fields for Urban Areas (4DGF)", authors:"", venue:"NeurIPS", year:2024, paper:"https://arxiv.org/abs/2406.03175", code:"https://github.com/tobiasfshr/map4d", project:"https://tobiasfshr.github.io/pub/4dgf/" },
                { title:"SCube: Instant Large-Scale Scene Reconstruction using VoxSplats", authors:"", venue:"NeurIPS", year:2024, paper:"https://arxiv.org/abs/2410.20030", code:"https://github.com/nv-tlabs/SCube", project:"https://research.nvidia.com/labs/toronto-ai/scube/" },
                { title:"HUGS: Holistic Urban 3D Scene Understanding via Gaussian Splatting", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2403.12722", code:"https://github.com/hyzhou404/HUGS", project:"https://xdimlab.github.io/hugs_website/" },
                { title:"MagicDrive3D: Controllable 3D Generation for Any-View Rendering in Street Scenes", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2405.14475", code:"https://github.com/flymin/MagicDrive3D", project:"https://gaoruiyuan.com/magicdrive3d/" },
                { title:"S3Gaussian: Self-Supervised Street Gaussians for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2405.20323", code:"https://github.com/nnanhuang/S3Gaussian/", project:"https://wzzheng.net/S3Gaussian/" },
                { title:"VDG: Vision-Only Dynamic Gaussian for Driving Simulation", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2406.18198", code:"https://github.com/lifuguan/VDG_official", project:"https://3d-aigc.github.io/VDG/" },
                { title:"UniGaussian: Driving Scene Reconstruction from Multiple Camera Models via Unified Gaussian Representations", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2411.15355", code:"#", project:"#"},
                { title:"Stag-1: Towards Realistic 4D Driving Simulation with Video Generation Model", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.05280", code:"https://github.com/wzzheng/Stag", project:"https://wzzheng.net/Stag/" },
                { title:"DrivingRecon: Large 4D Gaussian Reconstruction Model For Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.09043", code:"https://github.com/EnVision-Research/DriveRecon", project:"#"},
                { title:"OccScene: Semantic Occupancy-Based Cross-Task Mutual Learning for 3D Scene Generation", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.11183", code:"#", project:"#"},
                { title:"SGD: Street View Synthesis with Gaussian Splatting and Diffusion Prior", authors:"", venue:"WACV", year:2025, paper:"https://arxiv.org/abs/2403.20079", code:"#", project:"#"},
                { title:"OmniRe: Omni Urban Scene Reconstruction", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2408.16760", code:"https://github.com/ziyc/drivestudio", project:"https://ziyc.github.io/omnire/" },
                { title:"DriveDreamer4D: World Models Are Effective Data Machines for 4D Driving Scene Representation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2410.13571", code:"https://github.com/GigaAI-research/DriveDreamer4D", project:"https://drivedreamer4d.github.io/" },
                { title:"DeSiRe-GS: 4D Street Gaussians for Static-Dynamic Decomposition and Surface Reconstruction for Urban Driving Scenes", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.11921", code:"https://github.com/chengweialan/DeSiRe-GS", project:"#"},
                { title:"SplatAD: Real-Time Lidar and Camera Rendering with 3D Gaussian Splatting for Autonomous Driving", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.16816", code:"https://github.com/carlinds/splatad", project:"https://research.zenseact.com/publications/splatad/" },
                { title:"ReconDreamer: Crafting World Models for Driving Scene Reconstruction via Online Restoration", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.19548", code:"https://github.com/GigaAI-research/ReconDreamer/", project:"https://recondreamer.github.io/" },
                { title:"FreeSim: Toward Free-Viewpoint Camera Simulation in Driving Scenes", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2412.03566", code:"#", project:"https://drive-sim.github.io/freesim/" },
                { title:"StreetCrafter: Street View Synthesis with Controllable Video Diffusion Models", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2412.13188", code:"https://github.com/zju3dv/street_crafter", project:"https://zju3dv.github.io/street_crafter/" },
                { title:"FlexDrive: Toward Trajectory Flexibility in Driving Scene Reconstruction and Rendering", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2502.21093", code:"#", project:"#"},
                { title:"S-NeRF++: Autonomous Driving Simulation via Neural Reconstruction and Generation", authors:"", venue:"TPAMI", year:2025, paper:"https://arxiv.org/abs/2402.02112", code:"#", project:"#"},
                { title:"DreamDrive: Generative 4D Scene Modeling from Street View Images", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2501.00601", code:"#", project:"https://pointscoder.github.io/DreamDrive/" },
                { title:"Uni-Gaussians: Unifying Camera and Lidar Simulation with Gaussians for Dynamic Driving Scenarios", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.08317", code:"#", project:"https://zikangyuan.github.io/UniGaussians/" },
                { title:"MuDG: Taming Multi-Modal Diffusion with Gaussian Splatting for Urban Scene Reconstruction", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.10604", code:"https://github.com/heiheishuang/MuDG", project:"https://heiheishuang.xyz/mudg/" },
                { title:"SceneCrafter: Unraveling the Effects of Synthetic Data on End-to-End Autonomous Driving Humanoid Robots", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.18108", code:"https://github.com/cancaries/SceneCrafter", project:"#"},
                { title:"ReconDreamer++: Harmonizing Generative and Reconstructive Models for Driving Scene Representation", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.18438", code:"https://github.com/GigaAI-research/ReconDreamer-Plus", project:"https://recondreamer-plus.github.io/" },
                { title:"RealEngine: Simulating Autonomous Driving in Realistic Context", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.16902", code:"https://github.com/fudan-zvg/RealEngine", project:"#"},
                { title:"GeoDrive: 3D Geometry-Informed Driving World Model with Precise Action Control", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.22421", code:"https://github.com/antonioo-c/GeoDrive", project:"#"},
                { title:"Pseudo-Simulation for Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.04218", code:"https://github.com/autonomousvision/navsim", project:"#"},
                { title:"Dreamland: Controllable World Creation with Simulator and Generative Models", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.08006", code:"#", project:"https://metadriverse.github.io/dreamland/" }
              ]
            },
            occupancy: {
              A: [
              { title:"Diffusion Probabilistic Models for Scene-Scale 3D Categorical Data (SSD)", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2301.00527", code:"https://github.com/zoomin-lee/scene-scale-diffusion", project:"#"},
                { title:"SemCity: Semantic Scene Generation with Triplane Diffusion", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2403.07773", code:"https://github.com/zoomin-lee/SemCity", project:"https://sglab.kaist.ac.kr/SemCity/"},
                { title:"WoVoGen: World Volume-Aware Diffusion for Controllable Multi-Camera Driving Scene Generation", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2312.02934", code:"https://github.com/fudan-zvg/WoVoGen", project:"#"},
                { title:"Urban Scene Diffusion through Semantic Occupancy Map (UrbanDiff)", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2403.11697", code:"#", project:"https://metadriverse.github.io/urbandiff/"},
                { title:"DrivingSphere: Building A High-Fidelity 4D World for Closed-Loop Simulation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.11252", code:"https://github.com/yanty123/DrivingSphere", project:"https://yanty123.github.io/DrivingSphere/"},
                { title:"UniScene: Unified Occupancy-Centric Driving Scene Generation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2412.05435", code:"https://github.com/Arlo0o/UniScene-Unified-Occupancy-centric-Driving-Scene-Generation", project:"https://arlo0o.github.io/uniscene/"},
                { title:"OccScene: Semantic Occupancy-Based Cross-Task Mutual Learning for 3D Scene Generation", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.11183", code:"#", project:"#"},
                { title:"InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2412.03934", code:"https://github.com/nv-tlabs/InfiniCube", project:"https://research.nvidia.com/labs/toronto-ai/infinicube/"},
                { title:"Controllable 3D Outdoor Scene Generation via Scene Graphs (Control-3D-Scene)", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2503.07152", code:"https://github.com/yuhengliu02/control-3d-scene", project:"https://yuheng.ink/project-page/control-3d-scene/"},
                { title:"X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.13558", code:"https://github.com/yuyang-cloud/X-Scene", project:"https://x-scene.github.io/"},
              ],
              B: [
              { title:"Emergent-Occ: Differentiable Raycasting for Self-supervised Occupancy Forecasting", authors:"", venue:"ECCV", year:2022, paper:"https://arxiv.org/abs/2210.01917", code:"https://github.com/tarashakhurana/emergent-occ-forecasting", project:"#"},
                { title:"FF4D: Point Cloud Forecasting as a Proxy for 4D Occupancy Forecasting", authors:"", venue:"CVPR", year:2023, paper:"https://arxiv.org/abs/2302.13130", code:"https://github.com/tarashakhurana/4d-occ-forecasting", project:"https://www.cs.cmu.edu/~tkhurana/ff4d/index.html"},
                { title:"UniWorld: Autonomous Driving Pre-Training via World Models", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2308.07234", code:"#", project:"#"},
                { title:"UniScene: Multi-Camera Unified Pre-Training via 3D Scene Reconstruction for Autonomous Driving", authors:"", venue:"arXiv", year:2023, paper:"https://arxiv.org/abs/2305.18829", code:"https://github.com/chaytonmin/UniScene", project:"#"},
                { title:"OccWorld: Learning A 3D Occupancy World Model for Autonomous Driving", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2311.16038", code:"https://github.com/wzzheng/OccWorld", project:"https://wzzheng.net/OccWorld/"},
                { title:"Cam4DOcc: Benchmark for Camera-Only 4D Occupancy Forecasting", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2311.17663", code:"https://github.com/haomo-ai/Cam4DOcc", project:"#"},
                { title:"DriveWorld: 4D Pre-Trained Scene Understanding via World Models", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2405.04390", code:"#", project:"#"},
                { title:"OccSora: 4D Occupancy Generation Models as World Simulators", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2405.20337", code:"https://github.com/wzzheng/OccSora", project:"https://wzzheng.net/OccSora/"},
                { title:"UnO: Unsupervised Occupancy Fields for Perception and Forecasting", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2406.08691", code:"#", project:"https://waabi.ai/uno/"},
                { title:"LOPR: Self-Supervised Multi-Future Occupancy Forecasting", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2407.21126", code:"#", project:"#"},
                { title:"FSF-Net: Enhance 4D Occupancy Forecasting with Coarse BEV Scene Flow", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2409.15841", code:"#", project:"#"},
                { title:"OccLLaMA: An Occupancy-Language-Action Generative World Model", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2409.03272", code:"#", project:"#"},
                { title:"DOME: Taming Diffusion Model into High-Fidelity Controllable Occupancy World Model", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2410.10429", code:"https://github.com/gusongen/DOME", project:"https://gusongen.github.io/DOME"},
                { title:"GaussianAD: Gaussian-Centric End-to-End Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.10371", code:"https://github.com/wzzheng/GaussianAD", project:"https://wzzheng.net/GaussianAD"},
                { title:"DFIT-OccWorld: Efficient Occupancy World Model via Decoupled Dynamic Flow", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.13772", code:"#", project:"#"},
                { title:"Drive-OccWorld: Vision-Centric 4D Occupancy Forecasting and Planning", authors:"", venue:"AAAI", year:2025, paper:"https://arxiv.org/abs/2408.14197", code:"https://github.com/yuyang-cloud/Drive-OccWorld", project:"https://drive-occworld.github.io/"},
                { title:"PreWorld: Semi-Supervised Vision-Centric 3D Occupancy World Model", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2502.07309", code:"https://github.com/getterupper/PreWorld", project:"#"},
                { title:"OccProphet: Camera-Only 4D Occupancy Forecasting with Observer-Forecaster-Refiner", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2502.15180", code:"https://github.com/JLChen-C/OccProphet", project:"#"},
                { title:"RenderWorld: World Model with Self-Supervised 3D Label", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2409.11356", code:"#", project:"#"},
                { title:"Occ-LLM: Enhancing Driving with Occupancy-Based Large Language Models", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2502.06419", code:"#", project:"#"},
                { title:"EfficientOCF: Spatiotemporal Decoupling for Efficient Occupancy Forecasting", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.14169", code:"#", project:"#"},
                { title:"DIO: Decomposable Implicit 4D Occupancy-Flow World Model", authors:"", venue:"CVPR", year:2025, paper:"https://openaccess.thecvf.com/content/CVPR2025/papers/Diehl_DIO_Decomposable_Implicit_4D_Occupancy-Flow_World_Model_CVPR_2025_paper.pdf", code:"#", project:"#"},
                { title:"TÂ³Former: Temporal Triplane Transformers as Occupancy World Models", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.07338", code:"#", project:"#"},
                { title:"UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2503.24381", code:"https://github.com/tasl-lab/UniOcc", project:"https://huggingface.co/datasets/tasl-lab/uniocc"},
                { title:"IÂ²-World: Intra-Inter Tokenization for Efficient Dynamic 4D Scene Forecasting", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2507.09144", code:"https://github.com/lzzzzzm/II-World", project:"#"},
                { title:"COME: Adding Scene-Centric Forecasting Control to Occupancy World Model", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.13260", code:"https://github.com/synsin0/COME", project:"#"}
              ],
              C: [
              { title:"SemCity: Semantic Scene Generation with Triplane Diffusion", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2403.07773", code:"https://github.com/zoomin-lee/SemCity", project:"https://sglab.kaist.ac.kr/SemCity/"},
                { title:"XCube: Large-Scale 3D Generative Modeling using Sparse Voxel Hierarchies", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2312.03806", code:"https://github.com/nv-tlabs/XCube", project:"https://research.nvidia.com/labs/toronto-ai/xcube/"},
                { title:"PDD: Pyramid Diffusion for Fine 3D Large Scene Generation", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2311.12085", code:"https://github.com/yuhengliu02/pyramid-discrete-diffusion", project:"https://yuheng.ink/project-page/pyramid-discrete-diffusion"},
                { title:"OccSora: 4D Occupancy Generation Models as World Simulators for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2405.20337", code:"https://github.com/wzzheng/OccSora", project:"https://wzzheng.net/OccSora/"},
                { title:"DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2410.18084", code:"https://github.com/3DTopia/DynamicCity", project:"https://dynamic-city.github.io/"},
                { title:"DrivingSphere: Building A High-Fidelity 4D World for Closed-Loop Simulation", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2411.11252", code:"https://github.com/yanty123/DrivingSphere", project:"https://yanty123.github.io/DrivingSphere/"},
                { title:"InfiniCube: Unbounded and Controllable Dynamic 3D Driving Scene Generation with World-Guided Video Models", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2412.03934", code:"https://github.com/nv-tlabs/InfiniCube", project:"https://research.nvidia.com/labs/toronto-ai/infinicube/"},
                { title:"X-Scene: Large-Scale Driving Scene Generation with High Fidelity and Flexible Controllability", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.13558", code:"https://github.com/yuyang-cloud/X-Scene", project:"https://x-scene.github.io/"},
                { title:"PrITTI: Primitive-Based Generation of Controllable and Editable 3D Semantic Scenes", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2506.19117", code:"https://github.com/avg-dev/PrITTI", project:"https://raniatze.github.io/pritti/"}

              ]
            },
            lidar: {
              A: [
              { title:"DUSty: Learning to Drop Points for LiDAR Scan Synthesis", authors:"", venue:"IROS", year:2021, paper:"https://arxiv.org/abs/2102.11952", code:"https://github.com/kazuto1011/dusty-gan", project:"https://kazuto1011.github.io/dusty-gan/" },
                { title:"LiDARGen: Learning to Generate Realistic LiDAR Point Clouds", authors:"", venue:"ECCV", year:2022, paper:"https://arxiv.org/abs/2209.03954", code:"https://github.com/vzyrianov/lidargen", project:"#"},
                { title:"DUSty v2: Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data", authors:"", venue:"WACV", year:2023, paper:"https://arxiv.org/abs/2210.11750", code:"https://github.com/kazuto1011/dusty-gan-v2", project:"https://kazuto1011.github.io/dusty-gan-v2/"},
                { title:"UltraLiDAR: Learning Compact Representations for LiDAR Completion and Generation", authors:"", venue:"CVPR", year:2023, paper:"https://arxiv.org/abs/2311.01448", code:"#", project:"https://waabi.ai/ultralidar/"},
                { title:"Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion", authors:"", venue:"ICLR", year:2024, paper:"https://arxiv.org/abs/2311.01017", code:"#", project:"https://waabi.ai/research/copilot-4d"},
                { title:"R2DM: LiDAR Data Synthesis with Denoising Diffusion Probabilistic Models", authors:"", venue:"ICRA", year:2024, paper:"https://arxiv.org/abs/2309.09256", code:"https://github.com/kazuto1011/r2dm", project:"https://kazuto1011.github.io/r2dm"},
                { title:"ViDAR: Visual Point Cloud Forecasting enables Scalable Autonomous Driving", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2312.17655", code:"https://github.com/OpenDriveLab/ViDAR", project:"#"},
                { title:"LiDiff: Scaling Diffusion Models to Real-World 3D LiDAR Scene Completion", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2403.13470", code:"https://github.com/PRBonn/LiDiff", project:"#"},
                { title:"LiDM: Towards Realistic Scene Generation with LiDAR Diffusion Models", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2404.00815", code:"https://github.com/hancyran/LiDAR-Diffusion/tree/8416ddbbda881553088109a66badf71ff11999e0", project:"#"},
                { title:"RangeLDM: Fast Realistic LiDAR Point Cloud Generation", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2403.10094", code:"https://github.com/WoodwindHu/RangeLDM", project:"#"},
                { title:"Text2LiDAR: Text-Guided LiDAR Point Cloud Generation via Equirectangular Transformer", authors:"", venue:"ECCV", year:2024, paper:"https://arxiv.org/abs/2407.19628", code:"https://github.com/wuyang98/Text2LiDAR", project:"#"},
                { title:"LiDARGRIT: Taming Transformers for Realistic Lidar Point Cloud Generation", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2404.05505", code:"https://github.com/hamedhaghighi/LidarGRIT", project:"#"},
                { title:"BEVWorld: A Multimodal World Simulator for Autonomous Driving via Scene-Level BEV Latents", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2407.05679", code:"https://github.com/zympsyche/BevWorld", project:"#"},
                { title:"SDS: Simultaneous Diffusion Sampling for Conditional LiDAR Generation", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2410.11628", code:"#", project:"#"},
                { title:"DiffSSC: Semantic LiDAR Scan Completion using Denoising Diffusion Probabilistic Models", authors:"", venue:"IROS", year:2025, paper:"https://arxiv.org/abs/2409.18092", code:"#", project:"#"},
                { title:"HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.01407", code:"#", project:"#"},
                { title:"LOGen: Toward Lidar Object Generation by Point Diffusion", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.07385", code:"https://github.com/valeoai/LOGen", project:"https://nerminsamet.github.io/logen/"},
                { title:"OLiDM: Object-Aware LiDAR Diffusion Models for Autonomous Driving", authors:"", venue:"AAAI", year:2025, paper:"https://arxiv.org/abs/2412.17226", code:"https://github.com/yanty123/OLiDM", project:"https://yanty123.github.io/OLiDM"},
                { title:"X-Drive: Cross-Modality Consistent Multi-Sensor Data Synthesis for Driving Scenarios", authors:"", venue:"ICLR", year:2025, paper:"https://arxiv.org/abs/2411.01123", code:"https://github.com/yichen928/X-Drive", project:"#"},
                { title:"LidarDM: Generative LiDAR Simulation in a Generated World", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2404.02903", code:"https://github.com/vzyrianov/lidardm", project:"https://zyrianov.org/lidardm/"},
                { title:"LiDAR-EDIT: LiDAR Data Generation by Editing the Object Layouts in Real-World Scenes", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2412.00592", code:"https://github.com/HoAdrian/ICRA2025_lidar_edit", project:"https://sites.google.com/view/lidar-edit"},
                { title:"R2Flow: Fast LiDAR Data Generation with Rectified Flows", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2412.02241", code:"https://github.com/kazuto1011/r2flow", project:"https://kazuto1011.github.io/r2flow/"},
                { title:"WeatherGen: A Unified Diverse Weather Generator for LiDAR Point Clouds via Spider Mamba Diffusion", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2504.13561", code:"https://github.com/wuyang98/weathergen", project:"#"},
                { title:"LiDPM: Rethinking Point Diffusion for Lidar Scene Completion", authors:"", venue:"IV", year:2025, paper:"https://arxiv.org/abs/2504.17791", code:"https://github.com/astra-vision/LiDPM", project:"https://astra-vision.github.io/LiDPM/"},
                { title:"HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2501.14729", code:"https://github.com/LMD0311/HERMES", project:"https://lmd0311.github.io/HERMES/"},
                { title:"SuperPC: A Single Diffusion Model for Point Cloud Completion, Upsampling, Denoising, and Colorization", authors:"", venue:"CVPR", year:2025, paper:"https://arxiv.org/abs/2503.14558", code:"#", project:"https://sairlab.org/superpc/"},
                { title:"3DiSS: Towards Generating Realistic 3D Semantic Training Data for Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2503.21449", code:"https://github.com/PRBonn/3DiSS", project:"#"},
                { title:"Distill-DPO: Diffusion Distillation With Direct Preference Optimization For Efficient 3D LiDAR Scene Completion", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2504.11447", code:"https://github.com/happyw1nd/DistillationDPO", project:"#"},
                { title:"DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.19239", code:"#", project:"#"},
                { title:"OpenDWM: Open Driving World Models", authors:"", venue:"arXiv", year:2025, paper:"https://github.com/SenseTime-FVG/OpenDWM", code:"https://github.com/SenseTime-FVG/OpenDWM", project:"#"},
                { title:"SPIRAL: Semantic-Aware Progressive LiDAR Scene Generation", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.22643", code:"#", project:"#"},
                { title:"La La LiDAR: Large-Scale Layout Generation from LiDAR Data", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2508.03691", code:"#", project:"#"},
                { title:"Veila: Panoramic LiDAR Generation from a Monocular RGB Image", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2508.03690", code:"#", project:"#"},
                { title:"LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2508.03692", code:"https://github.com/lidarcrafter/toolkit", project:"https://lidarcrafter.github.io/" }
  
              ],
              B: [
              { title:"Copilot4D: Learning Unsupervised World Models for Autonomous Driving via Discrete Diffusion", authors:"", venue:"ICLR", year:2024, paper:"https://arxiv.org/abs/2311.01017", code:"#", project:"https://waabi.ai/research/copilot-4d"},
                { title:"Visual Point Cloud Forecasting enables Scalable Autonomous Driving (ViDAR)", authors:"", venue:"CVPR", year:2024, paper:"https://arxiv.org/abs/2312.17655", code:"https://github.com/OpenDriveLab/ViDAR", project:"#"},
                { title:"BEVWorld: A Multimodal World Simulator for Autonomous Driving via Scene-Level BEV Latents", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2407.05679", code:"https://github.com/zympsyche/BevWorld", project:"#"},
                { title:"HERMES: A Unified Self-Driving World Model for Simultaneous 3D Scene Understanding and Generation", authors:"", venue:"ICCV", year:2025, paper:"https://arxiv.org/abs/2501.14729", code:"https://github.com/LMD0311/HERMES", project:"https://lmd0311.github.io/HERMES/"},
                { title:"DriveX: Omni Scene Modeling for Learning Generalizable World Knowledge in Autonomous Driving", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2505.19239", code:"#", project:"#"}
              ],
              C: [
              { title:"HoloDrive: Holistic 2D-3D Multi-Modal Street Scene Generation for Autonomous Driving", authors:"", venue:"arXiv", year:2024, paper:"https://arxiv.org/abs/2412.01407", code:"#", project:"#"},
                { title:"LidarDM: Generative LiDAR Simulation in a Generated World", authors:"", venue:"ICRA", year:2025, paper:"https://arxiv.org/abs/2404.02903", code:"https://github.com/vzyrianov/lidardm", project:"https://zyrianov.org/lidardm/"},
                { title:"OpenDWM: Open Driving World Models", authors:"", venue:"arXiv", year:2025, paper:"https://github.com/SenseTime-FVG/OpenDWM", code:"https://github.com/SenseTime-FVG/OpenDWM", project:"#"},
                { title:"LiDARCrafter: Dynamic 4D World Modeling from LiDAR Sequences", authors:"", venue:"arXiv", year:2025, paper:"https://arxiv.org/abs/2508.03692", code:"https://github.com/lidarcrafter/toolkit", project:"https://lidarcrafter.github.io/" }
              ]
            }
          };
    
          (function initAllPapersSections(){
            document.querySelectorAll('.papers-section').forEach(section => initPapersSection(section));
          })();
    
          function initPapersSection(root){
            const sectionKey = root.getAttribute('data-section-key'); // video / occupancy / lidar
            const tabs = Array.from(root.querySelectorAll('.tab-btn'));
            const panels = {
              A: root.querySelector(`[id$="panel-a"]`),
              B: root.querySelector(`[id$="panel-b"]`),
              C: root.querySelector(`[id$="panel-c"]`),
              D: root.querySelector(`[id$="panel-d"]`),
            };
            const lists = {
              A: panels.A.querySelector('.list'),
              B: panels.B.querySelector('.list'),
              C: panels.C.querySelector('.list'),
              D: panels.D.querySelector('.list')
            };
            const countEl = root.querySelector('.count');
            const searchInput = root.querySelector('.paper-search');
    
            let activeKey = 'A';
            let keyword = '';
    
            function makeLink(label, href){
              const a = document.createElement('a');
              a.className = 'link';
              a.textContent = label;
              a.href = href || '#';
              a.target = '_blank';
              a.rel = 'noopener noreferrer';
              return a;
            }
            function makeCard(item, badgeIdx=1){
              const wrap = document.createElement('article');
              wrap.className = 'card';
    
              const dot = document.createElement('span');
              dot.className = 'badge' + (badgeIdx===2?' badge-2': (badgeIdx===3?' badge-3':(badgeIdx===4?' badge-4':'')));
              wrap.appendChild(dot);
    
              const box = document.createElement('div');
              const h3 = document.createElement('h3');
              h3.textContent = item.title || 'Untitled';
              const meta = document.createElement('div');
              meta.className = 'meta';
              meta.textContent = [
                item.authors || '',
                item.venue ? `${item.venue}${item.year?` Â· ${item.year}`:''}` : (item.year||'')
              ].filter(Boolean).join(' | ');
    
              const links = document.createElement('div');
              links.className = 'links';
              links.appendChild(makeLink('Paper', item.paper));
              links.appendChild(makeLink('Code', item.code));
              links.appendChild(makeLink('Project', item.project));
    
              box.appendChild(h3);
              box.appendChild(meta);
              box.appendChild(links);
              wrap.appendChild(box);
              return wrap;
            }
    
            const normalize = s => (s||'').toLowerCase();
            function match(item, kw){
              if(!kw) return true;
              const bag = [item.title, item.authors, item.venue, item.year]
                .map(x=>String(x??'')).join(' ').toLowerCase();
              return bag.includes(kw);
            }
    
            function renderList(subKey){
                const INITIAL = Number(root.dataset.initial || 3); // é»˜è®¤ 3
                const data = (paperStore[sectionKey] && paperStore[sectionKey][subKey]) || [];
                const items = data.filter(it=>match(it, keyword));

                const panelEl = panels[subKey];
                const listEl  = lists[subKey];

                let ctrlEl = panelEl.querySelector('.showmore-wrap');
                if(!ctrlEl){
                    ctrlEl = document.createElement('div');
                    ctrlEl.className = 'showmore-wrap';
                    panelEl.appendChild(ctrlEl);
                }

                if(panelEl.dataset.expanded === undefined){
                    panelEl.dataset.expanded = "false";
                }
                const expanded = panelEl.dataset.expanded === "true";

                const shown = expanded ? items : items.slice(0, INITIAL);

                listEl.innerHTML = '';
                if(items.length===0){
                    const empty = document.createElement('div');
                    empty.className = 'empty';
                    empty.textContent = 'No data or no match.';
                    listEl.appendChild(empty);
                    ctrlEl.innerHTML = '';
                    countEl.textContent = `0 items`;
                    return;
                }
                shown.forEach(it => listEl.appendChild(makeCard(
                    it, subKey==='A'?1: subKey==='B'?2: subKey==='C'?3:4
                )));

                countEl.textContent = `${shown.length}/${items.length} items`;

                if(items.length > INITIAL){
                    ctrlEl.innerHTML = `
                    <button class="showmore-btn" type="button">
                        ${expanded ? "Collapse" : `Expand (${items.length - INITIAL})`}
                    </button>`;
                    const btn = ctrlEl.querySelector('button');
                    btn.onclick = () => {
                    panelEl.dataset.expanded = expanded ? "false" : "true";
                    renderList(subKey);
                    };
                }else{
                    ctrlEl.innerHTML = '';
                }
                }

    
            function switchTo(subKey){
              activeKey = subKey;
              panels[activeKey].dataset.expanded = "false";
              tabs.forEach(btn=>{
                const isSelected = btn.id.endsWith(subKey.toLowerCase());
                btn.setAttribute('aria-selected', String(isSelected));
              });
              Object.entries(panels).forEach(([k,el])=>{
                el.setAttribute('aria-hidden', String(k!==subKey));
              });
              renderList(subKey);
            }
    
            // events
            tabs.forEach(btn=>{
              btn.addEventListener('click', ()=>{
                const subKey = btn.id.split('-').pop().toUpperCase(); // a/b/c
                switchTo(subKey);
              });
            });
            root.addEventListener('keydown', (e)=>{
            if(e.key==='ArrowRight' || e.key==='ArrowLeft'){
                e.preventDefault();
                const order = ['A','B','C','D'].filter(k => panels[k]);
                const idx = order.indexOf(activeKey);
                const len = order.length;
                const next = e.key==='ArrowRight' ? (idx+1)%len : (idx-1+len)%len;
                switchTo(order[next]);
                root.querySelector(`[id$="tab-${order[next].toLowerCase()}"]`)?.focus();
            }
            });
            searchInput.addEventListener('input', ()=>{
              keyword = normalize(searchInput.value);
              renderList(activeKey);
            });
            searchInput.addEventListener('search', ()=>{
              keyword = normalize(searchInput.value);
              renderList(activeKey);
            });
    
            // init
            switchTo('A');
          }
        </script>

        <script>
            // å¯¹é¡µé¢ä¸Šæ¯ä¸ª .videogen ç‹¬ç«‹åˆå§‹åŒ–
            document.querySelectorAll('.videogen').forEach((root) => {
            const heroVideo  = root.querySelector('[data-hero]');
            const heroSource = heroVideo.querySelector('source');
            const heroLabel  = root.querySelector('[data-hero-label]');
            const thumbs     = Array.from(root.querySelectorAll('.thumb'));
        
            function setActive(btn) {
                thumbs.forEach(b => {
                const on = b === btn;
                b.classList.toggle('is-active', on);
                b.setAttribute('aria-selected', on ? 'true' : 'false');
                });
            }
        
            function switchTo(btn) {
                const src = btn.getAttribute('data-src');
                if (!src) return;
                const label = btn.getAttribute('data-label') || 'Video';
                heroSource.src = src;
                heroVideo.load();
                heroVideo.play().catch(()=>{});
                if (heroLabel) heroLabel.textContent = label;
                setActive(btn);
            }
        
            // ç‚¹å‡»åˆ‡æ¢ï¼ˆä»…ä½œç”¨äºŽæœ¬ç»„ï¼‰
            thumbs.forEach(btn => btn.addEventListener('click', () => switchTo(btn)));
        
            // é”®ç›˜å·¦å³åˆ‡æ¢ï¼ˆä»…å½“è¯¥ç»„èŽ·å¾—ç„¦ç‚¹æ—¶ç”Ÿæ•ˆï¼‰
            root.addEventListener('keydown', (e) => {
                if (e.key !== 'ArrowLeft' && e.key !== 'ArrowRight') return;
                const idx = thumbs.findIndex(b => b.classList.contains('is-active'));
                if (idx === -1) return;
                const next = e.key === 'ArrowRight'
                ? (idx + 1) % thumbs.length
                : (idx - 1 + thumbs.length) % thumbs.length;
                switchTo(thumbs[next]);
                thumbs[next].scrollIntoView({ behavior: 'smooth', inline: 'center', block: 'nearest' });
            });
        
            // è‹¥æ ‡è®°äº† is-activeï¼Œåˆ™ç”¨å®ƒä½œä¸ºåˆå§‹ï¼›å¦åˆ™æ²¿ç”¨ <source> é»˜è®¤
            const initial = root.querySelector('.thumb.is-active');
            if (initial) switchTo(initial);
            });
        </script>
  
        <script>
          (function(){
            function buildSrc(client, base, method, file, query){
              // ç»„åˆ viser-client çš„ URL
              // e.g. https://.../viser-client/?playbackPath=https://.../lidar_visers/lidargen/0.viser&initialCamera...
              const slash = base.endsWith('/') ? '' : '/';
              return `${client}?playbackPath=${base}${slash}${method}/${file}${query || ''}`;
            }
          
            document.querySelectorAll('.data-switcher').forEach((root)=>{
              // ä½œç”¨åŸŸï¼šæ¯ä¸ª data-switcher ç‹¬ç«‹
              const client = root.dataset.client;
              const base   = root.dataset.base;
              const query  = root.dataset.query || '';
              const iframes = Array.from(root.querySelectorAll('iframe[data-file]'));
              const btns    = Array.from(root.querySelectorAll('.method-btn'));
          
              if(!client || !base || iframes.length===0 || btns.length===0) return;
          
              let inited = false;
          
              function setActive(btn){
                btns.forEach(b=>{
                  const on = b===btn;
                  b.classList.toggle('is-active', on);
                  b.setAttribute('aria-selected', on ? 'true' : 'false');
                });
              }
          
              function switchMethod(btn){
                const method = btn.getAttribute('data-method');
                if(!method) return;
                iframes.forEach(ifr=>{
                  const file = ifr.getAttribute('data-file'); // å¦‚ 0.viser / 1.viser
                  if(!file) return;
                  const next = buildSrc(client, base, method, file, query);
                  if(ifr.src !== next){
                    ifr.src = next; // æ‡’åŠ è½½æˆ–åˆ‡æ¢æ—¶æ‰å¡«å……
                  }
                });
                setActive(btn);
              }
          
              function initOnce(){
                if(inited) return;
                inited = true;
                const first = root.querySelector('.method-btn.is-active') || btns[0];
                if(first) switchMethod(first);
              }
          
              // ç‚¹å‡»åˆ‡æ¢ï¼ˆä»…å½±å“å½“å‰å®¹å™¨ï¼‰
              btns.forEach(btn=>btn.addEventListener('click', ()=>switchMethod(btn)));
          
              // å±•å¼€ <details> æ—¶å†åˆå§‹åŒ–ï¼Œå‡å°‘é¦–å±è¯·æ±‚é‡
              root.addEventListener('toggle', ()=>{
                if(root.open) initOnce();
              });
              if(root.open) initOnce();       // å¦‚æžœé»˜è®¤æ˜¯å±•å¼€çŠ¶æ€ï¼Œç«‹åˆ»åˆå§‹åŒ–
          
              // é”®ç›˜å·¦å³é”®åˆ‡æ¢ï¼ˆå®¹å™¨èšç„¦ï¼‰
              root.tabIndex = 0;
              root.addEventListener('keydown', (e)=>{
                if(e.key!=='ArrowLeft' && e.key!=='ArrowRight') return;
                const idx = btns.findIndex(b=>b.classList.contains('is-active'));
                if(idx < 0) return;
                const next = e.key==='ArrowRight' ? (idx+1)%btns.length : (idx-1+btns.length)%btns.length;
                switchMethod(btns[next]);
                btns[next].scrollIntoView({ behavior:'smooth', inline:'center', block:'nearest' });
              });
            });
          })();
          </script>
    

    </body>
</html>
